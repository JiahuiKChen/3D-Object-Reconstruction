{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voxel-VAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "9zoWjOlQLw6j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Setup :)\n",
        "import numpy as np\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Flatten, Conv3D, Dense, Conv1D, Input\n",
        "from keras.engine.input_layer import Input\n",
        "from keras.losses import logcosh\n",
        "\n",
        "# Uses Keras functional API: https://keras.io/getting-started/functional-api-guide/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PvUYX57We-mV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: LOSS FUNCTION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-9xhY76bMaPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "b64cca75-af9c-4c87-9d87-79bb434ba4cd"
      },
      "cell_type": "code",
      "source": [
        "########################## ENCODER NETWORK #################################\n",
        "# 5 layers\n",
        "# starts with 32x32x32 input, ends with Fully Connected layer (flattened 7x7x7 output of 4th convolutional layer)\n",
        "\n",
        "# ???\n",
        "# Glorot initialization is deafault (glorot_uniform) - Keras has glorot_normal \n",
        "# and glorot_uniform, paper is unclear which should be used\n",
        "\n",
        "# Input is 32x32x32 point cloud\n",
        "inputs = Input(shape=(32, 32, 32, 1))\n",
        "\n",
        "# First convolutional layer: outputs 30x30x30\n",
        "encode_c1 = Conv3D(8, kernel_size=3, activation='elu', padding='valid',\n",
        "              data_format='channels_last')(inputs)\n",
        "encode_b1 = BatchNormalization()(encode_c1)\n",
        "\n",
        "# Second convolutional layer: outputs 15x15x15 (downsamples via striding)\n",
        "encode_c2 = Conv3D(16, kernel_size=3, activation='elu', padding='same',\n",
        "              strides=(2, 2, 2))(encode_b1)\n",
        "encode_b2 = BatchNormalization()(encode_c2)\n",
        "\n",
        "# Third convolutional layer: outputs 13x13x13\n",
        "encode_c3 = Conv3D(32, kernel_size=3, activation='elu', padding='valid')(encode_b2)\n",
        "encode_b3 = BatchNormalization()(encode_c3)\n",
        "\n",
        "# Fourth convolutional layer: outputs 7x7x7 (downsamples via striding)\n",
        "encode_c4 = Conv3D(64, kernel_size=3, activation='elu', padding='same', \n",
        "              strides=(2, 2, 2))(encode_b3)\n",
        "encode_b4 = BatchNormalization()(encode_c4)\n",
        "\n",
        "# Fifth layer, fully connected: outputs 343\n",
        "encode_f5 = Flatten()(encode_b4)\n",
        "\n",
        "encoder = Model(inputs=inputs, outputs=encode_f5)\n",
        "\n",
        "# Structure/info about encoder\n",
        "encoder.compile(optimizer='adam', loss='logcosh', metrics=['accuracy'])\n",
        "encoder.summary()\n",
        "\n",
        "# Testing encoder on dummy data\n",
        "dummy_data = np.random.rand(100, 32, 32, 32, 1)\n",
        "# Labels don't matter for us, we only care about the model's ouptut, output must be in the shape of final layer!!!\n",
        "dumb_labels = np.random.rand(100, 21952)\n",
        "  \n",
        "encoder.fit(dummy_data, dumb_labels, shuffle=True)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        (None, 32, 32, 32, 1)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_96 (Conv3D)           (None, 30, 30, 30, 8)     224       \n",
            "_________________________________________________________________\n",
            "batch_normalization_89 (Batc (None, 30, 30, 30, 8)     32        \n",
            "_________________________________________________________________\n",
            "conv3d_97 (Conv3D)           (None, 15, 15, 15, 16)    3472      \n",
            "_________________________________________________________________\n",
            "batch_normalization_90 (Batc (None, 15, 15, 15, 16)    64        \n",
            "_________________________________________________________________\n",
            "conv3d_98 (Conv3D)           (None, 13, 13, 13, 32)    13856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_91 (Batc (None, 13, 13, 13, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv3d_99 (Conv3D)           (None, 7, 7, 7, 64)       55360     \n",
            "_________________________________________________________________\n",
            "batch_normalization_92 (Batc (None, 7, 7, 7, 64)       256       \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 21952)             0         \n",
            "=================================================================\n",
            "Total params: 73,392\n",
            "Trainable params: 73,152\n",
            "Non-trainable params: 240\n",
            "_________________________________________________________________\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.4916 - acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2d12970e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "rF-4rPBy5Sz9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########################## LATENT LAYER #################################\n",
        "\n",
        "# Sixth layer - LATENT LAYER: outputs 100\n",
        "latent = Dense(100, use_bias=True, activation='elu')(encode_f5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_WBpRlZn0YhE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########################## DECODER NETWORK ################################# \n",
        "\n",
        "# Fully connected layer that takes latent space as input\n",
        "vae.add(Dense(343, use_bias=True, activation='elu'))\n",
        "\n",
        "# Convolution layer that convolutes fully connected layer into 7x7x7\n",
        "vae.add(Conv1D(64, kernel_size=3, activation='elu', padding='same'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S4mT8h0T8NuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# OLD ENCODER NETWORK IMPLEMENTATION: (doesn't use functional keras)\n",
        "# vae = Sequential()\n",
        "# # First convolutional layer\n",
        "# vae.add(Conv3D(8, kernel_size=3, activation='elu', padding='valid', \n",
        "#                    data_format='channels_last', input_shape=(32, 32, 32, 1))) \n",
        "# vae.add(BatchNormalization())\n",
        "\n",
        "# # Second convolutional layer, downsampling through strided convolutions \n",
        "# # (default striding is 1x1x1, so up this to 2x2x2)\n",
        "# vae.add(Conv3D(16, kernel_size=3, activation='elu', padding='same', strides=(2, 2, 2))) \n",
        "# vae.add(BatchNormalization())\n",
        "\n",
        "# # # Third convolutional layer\n",
        "# vae.add(Conv3D(32, kernel_size=3, activation='elu', padding='valid'))\n",
        "# vae.add(BatchNormalization())\n",
        "\n",
        "# # # Fourth convolutional layer, downsampling through strided convolutions\n",
        "# vae.add(Conv3D(64, kernel_size=3, activation='elu', padding='same', strides=(2, 2, 2)))\n",
        "# vae.add(BatchNormalization())\n",
        "\n",
        "# # # Fully connected layer and latent layer\n",
        "# # # Fully connected: Dense layer that takes in flattened output of previous layer \n",
        "# # # Latent layer: output of fully connected layer is 100 dimensional latent space\n",
        "# vae.add(Flatten())\n",
        "# vae.add(Dense(100, use_bias=True, activation='elu'))\n",
        "\n",
        "# vae.compile(optimizer='adam', loss='logcosh', metrics=['accuracy'])\n",
        "# vae.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}