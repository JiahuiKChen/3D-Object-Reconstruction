{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voxel-VAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JiahuiKChen/3D-Object-Reconstruction/blob/master/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9zoWjOlQLw6j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Setup :)\n",
        "import numpy as np\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Flatten, Conv3D, Dense, Conv1D, Input, Reshape, Conv3DTranspose\n",
        "from keras.engine.input_layer import Input\n",
        "from keras.losses import logcosh\n",
        "\n",
        "# Uses Keras functional API: https://keras.io/getting-started/functional-api-guide/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PvUYX57We-mV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: LOSS FUNCTION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-9xhY76bMaPd",
        "colab_type": "code",
        "outputId": "0683e9bf-474a-44ba-93e1-db21c0429628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "########################## ENCODER NETWORK #################################\n",
        "# 5 layers\n",
        "# starts with 32x32x32 input, ends with Fully Connected layer (flattened 7x7x7 output of 4th convolutional layer)\n",
        "\n",
        "# ???\n",
        "# Glorot initialization is deafault (glorot_uniform) - Keras has glorot_normal \n",
        "# and glorot_uniform, paper is unclear which should be used\n",
        "\n",
        "# Input is 32x32x32 point cloud\n",
        "inputs = Input(shape=(32, 32, 32, 1))\n",
        "\n",
        "# First convolutional layer: outputs 30x30x30\n",
        "encode_c1 = Conv3D(8, kernel_size=3, activation='elu', padding='valid',\n",
        "              data_format='channels_last')(inputs)\n",
        "encode_b1 = BatchNormalization()(encode_c1)\n",
        "\n",
        "# Second convolutional layer: outputs 15x15x15 (downsamples via striding)\n",
        "encode_c2 = Conv3D(16, kernel_size=3, activation='elu', padding='same',\n",
        "              strides=(2, 2, 2))(encode_b1)\n",
        "encode_b2 = BatchNormalization()(encode_c2)\n",
        "\n",
        "# Third convolutional layer: outputs 13x13x13\n",
        "encode_c3 = Conv3D(32, kernel_size=3, activation='elu', padding='valid')(encode_b2)\n",
        "encode_b3 = BatchNormalization()(encode_c3)\n",
        "\n",
        "# Fourth convolutional layer: outputs 7x7x7 (downsamples via striding)\n",
        "encode_c4 = Conv3D(64, kernel_size=3, activation='elu', padding='same', \n",
        "              strides=(2, 2, 2))(encode_b3)\n",
        "encode_b4 = BatchNormalization()(encode_c4)\n",
        "\n",
        "# Fifth layer, fully connected: outputs 343\n",
        "encode_f5 = Flatten()(encode_b4)\n",
        "encode_b5 = BatchNormalization()(encode_f5)\n",
        "\n",
        "encoder = Model(inputs=inputs, outputs=encode_f5)\n",
        "\n",
        "# Structure/info about encoder\n",
        "encoder.compile(optimizer='adam', loss='logcosh', metrics=['accuracy'])\n",
        "encoder.summary()\n",
        "\n",
        "# Testing encoder on dummy data\n",
        "dummy_data = np.random.rand(100, 32, 32, 32, 1)\n",
        "# Labels don't matter for us, we only care about the model's ouptut, output must be in the shape of final layer!!!\n",
        "dumb_labels = np.random.rand(100, 21952)\n",
        "encoder.fit(dummy_data, dumb_labels, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_39 (InputLayer)        (None, 32, 32, 32, 1)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_120 (Conv3D)          (None, 30, 30, 30, 8)     224       \n",
            "_________________________________________________________________\n",
            "batch_normalization_113 (Bat (None, 30, 30, 30, 8)     32        \n",
            "_________________________________________________________________\n",
            "conv3d_121 (Conv3D)          (None, 15, 15, 15, 16)    3472      \n",
            "_________________________________________________________________\n",
            "batch_normalization_114 (Bat (None, 15, 15, 15, 16)    64        \n",
            "_________________________________________________________________\n",
            "conv3d_122 (Conv3D)          (None, 13, 13, 13, 32)    13856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_115 (Bat (None, 13, 13, 13, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv3d_123 (Conv3D)          (None, 7, 7, 7, 64)       55360     \n",
            "_________________________________________________________________\n",
            "batch_normalization_116 (Bat (None, 7, 7, 7, 64)       256       \n",
            "_________________________________________________________________\n",
            "flatten_28 (Flatten)         (None, 21952)             0         \n",
            "=================================================================\n",
            "Total params: 73,392\n",
            "Trainable params: 73,152\n",
            "Non-trainable params: 240\n",
            "_________________________________________________________________\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.4915 - acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2d0c67aad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "rF-4rPBy5Sz9",
        "colab_type": "code",
        "outputId": "536fbf64-63a7-406f-d8b8-a36f841b847a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "########################## LATENT LAYER #################################\n",
        "# \"All but the output layer are Batch Normalized\" - this is interpreted as the output \n",
        "# layer of the sigmoid AND the latent layer are not Batch Normalized but ???\n",
        "\n",
        "# input of latent layer is last layer of encoder network\n",
        "latent_input = Input(shape=(21952,))\n",
        "\n",
        "# Sixth layer - LATENT LAYER: outputs 100\n",
        "latent = Dense(100, use_bias=True, activation='elu')(latent_input)\n",
        "\n",
        "latent_layer = Model(inputs=latent_input, outputs=latent)\n",
        "\n",
        "# Structure/info about latent layer\n",
        "latent_layer.compile(optimizer='adam', loss='logcosh', metrics=['accuracy'])\n",
        "latent_layer.summary()\n",
        "\n",
        "# Testing latent layer on dummy data\n",
        "dummy_data = np.random.rand(100, 21952)\n",
        "fake_labels = np.random.rand(100, 100) \n",
        "latent_layer.fit(dummy_data, fake_labels, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_38 (InputLayer)        (None, 21952)             0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 100)               2195300   \n",
            "=================================================================\n",
            "Total params: 2,195,300\n",
            "Trainable params: 2,195,300\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 4s 44ms/step - loss: 2.2639 - acc: 0.0200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2d0ccb6690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "metadata": {
        "id": "_WBpRlZn0YhE",
        "colab_type": "code",
        "outputId": "eafe0f74-b52a-49a7-d322-b34d37eff807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "cell_type": "code",
      "source": [
        "########################## DECODER NETWORK ################################# \n",
        "\n",
        "# Latent space of 1D dimension 100 is input for decoder\n",
        "decoder_input = Input(shape=(100,))\n",
        "\n",
        "# First layer of decoder, fully connected layer: outputs 343\n",
        "decode_f1 = Dense(343, use_bias=True, activation='elu')(decoder_input)\n",
        "decode_b1 = BatchNormalization()(decode_f1)\n",
        "\n",
        "# Reshape layer from fully connected to 7x7x7\n",
        "# must add spacial dimension for convolutions to work\n",
        "decode_reshape = Reshape((7, 7, 7, 1), input_shape=(343,))(decode_b1) \n",
        "# Second convolutional layer: convolutes fully connected layer into 7x7x7 (with 64 filters)\n",
        "# decode_c2 = Conv3DTranspose(64, kernel_size=3, activation='elu', \n",
        "#                    padding='same')(decode_reshape)\n",
        "\n",
        "# Second convolutional layer: convolutes fully connected layer into 7x7x7\n",
        "# ??? Not exactly sure how to get from 1D to 3D convolution...(dimension wise)\n",
        "# decode_reshape = Reshape((7, 7, 7, 1), input_shape=(343,))(decode_b1) # must add spacial dimension for convolutions to work\n",
        "decode_c2 = Conv3D(64, kernel_size=3, activation='elu', \n",
        "                   padding='same')(decode_reshape)\n",
        "decode_b2 = BatchNormalization()(decode_c2)\n",
        "\n",
        "# Third layer (second convolutional layer): outputs 15x15x15\n",
        "decode_c3 = Conv3DTranspose(32, kernel_size=3, activation='elu', \n",
        "                   padding='valid', strides=(2, 2, 2))(decode_b2)\n",
        "decode_b3 = BatchNormalization()(decode_c3)\n",
        "\n",
        "# Fourth convolutional layer: outputs 15x15x15\n",
        "decode_c4 = Conv3DTranspose(16, kernel_size=3, activation='elu', \n",
        "                   padding='same')(decode_b3)\n",
        "decode_b4 = BatchNormalization()(decode_c4)\n",
        "\n",
        "# Fifth convolutional layer: outputs 32x32x32 \n",
        "decode_c5 = Conv3DTranspose(8, kernel_size=3, activation='elu', \n",
        "                   padding='valid', strides=(2, 2, 2))(decode_b4)\n",
        "decode_b5 = BatchNormalization()(decode_c5)\n",
        "\n",
        "# OUTPUT LAYERRRRRRRR!!! Sigmoid function to output probability each voxel is filled\n",
        "\n",
        "##???? How to get rid of filter dimension???\n",
        "decode_output = Conv3DTranspose(8, kernel_size=3, activation='sigmoid', \n",
        "                   padding='same')(decode_b5)\n",
        "\n",
        "decoder = Model(inputs=decoder_input, outputs=decode_output)\n",
        "\n",
        "# Structure/info about decoder\n",
        "decoder.compile(optimizer='adam', loss='logcosh', metrics=['accuracy'])\n",
        "decoder.summary()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_88 (InputLayer)        (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 343)               34643     \n",
            "_________________________________________________________________\n",
            "batch_normalization_263 (Bat (None, 343)               1372      \n",
            "_________________________________________________________________\n",
            "reshape_43 (Reshape)         (None, 7, 7, 7, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv3d_168 (Conv3D)          (None, 7, 7, 7, 64)       1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization_264 (Bat (None, 7, 7, 7, 64)       256       \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_92 (Conv3DT (None, 15, 15, 15, 32)    55328     \n",
            "_________________________________________________________________\n",
            "batch_normalization_265 (Bat (None, 15, 15, 15, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_93 (Conv3DT (None, 15, 15, 15, 16)    13840     \n",
            "_________________________________________________________________\n",
            "batch_normalization_266 (Bat (None, 15, 15, 15, 16)    64        \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_94 (Conv3DT (None, 31, 31, 31, 8)     3464      \n",
            "_________________________________________________________________\n",
            "batch_normalization_267 (Bat (None, 31, 31, 31, 8)     32        \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_95 (Conv3DT (None, 31, 31, 31, 8)     1736      \n",
            "=================================================================\n",
            "Total params: 112,655\n",
            "Trainable params: 111,729\n",
            "Non-trainable params: 926\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S4mT8h0T8NuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# OLD ENCODER NETWORK IMPLEMENTATION: (doesn't use functional keras)\n",
        "# vae = Sequential()\n",
        "# # First convolutional layer\n",
        "# vae.add(Conv3D(8, kernel_size=3, activation='elu', padding='valid', \n",
        "#                    data_format='channels_last', input_shape=(32, 32, 32, 1))) \n",
        "# vae.add(BatchNormalization())\n",
        "\n",
        "# # Second convolutional layer, downsampling through strided convolutions \n",
        "# # (default striding is 1x1x1, so up this to 2x2x2)\n",
        "# vae.add(Conv3D(16, kernel_size=3, activation='elu', padding='same', strides=(2, 2, 2))) \n",
        "# vae.add(BatchNormalization())\n",
        "\n",
        "# # # Third convolutional layer\n",
        "# vae.add(Conv3D(32, kernel_size=3, activation='elu', padding='valid'))\n",
        "# vae.add(BatchNormalization())\n",
        "\n",
        "# # # Fourth convolutional layer, downsampling through strided convolutions\n",
        "# vae.add(Conv3D(64, kernel_size=3, activation='elu', padding='same', strides=(2, 2, 2)))\n",
        "# vae.add(BatchNormalization())\n",
        "\n",
        "# # # Fully connected layer and latent layer\n",
        "# # # Fully connected: Dense layer that takes in flattened output of previous layer \n",
        "# # # Latent layer: output of fully connected layer is 100 dimensional latent space\n",
        "# vae.add(Flatten())\n",
        "# vae.add(Dense(100, use_bias=True, activation='elu'))\n",
        "\n",
        "# vae.compile(optimizer='adam', loss='logcosh', metrics=['accuracy'])\n",
        "# vae.summary()\n",
        "\n",
        "\n",
        "# OLD DECODER NETWORK IMPLEMENTATION\n",
        "# # First layer of decoder\n",
        "# vae.add(Dense(343, use_bias=True, activation='elu'))\n",
        "\n",
        "# # Convolution layer that convolutes fully connected layer into 7x7x7\n",
        "# vae.add(Conv1D(64, kernel_size=3, activation='elu', padding='same'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}