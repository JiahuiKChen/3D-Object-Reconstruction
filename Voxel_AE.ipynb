{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voxel-AE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JiahuiKChen/3D-Object-Reconstruction/blob/master/Voxel_AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9zoWjOlQLw6j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Setup :)\n",
        "import numpy as np\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Flatten, Conv3D, Dense, Conv1D, Input, Reshape, Conv3DTranspose\n",
        "from keras.engine.input_layer import Input\n",
        "from keras.losses import logcosh\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "# Uses Keras functional API: https://keras.io/getting-started/functional-api-guide/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PvUYX57We-mV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "################### MODIFIED BINARY CROSS ENTROPY LOSS FUNCTION ############\n",
        "# Binary cross entropy but with a lambda parameter that \n",
        "# encourages false positives and discourage false negatives (because of the high\n",
        "# amounts of blank voxels, without this term the model would output empty voxels)\n",
        "def lambda_binary_crossentropy(y_true, y_pred):\n",
        "  output = K.clip(y_pred, 0.1, 1)\n",
        "  binary_entr = -0.97 * y_true * K.log(output) - (0.03) * (1-y_true) * K.log(1-output)\n",
        "  \n",
        "  # getting tensor values into scalar\n",
        "  loss = K.sum(binary_entr, axis=1)\n",
        "  scalar_loss = K.mean(loss)  \n",
        "  \n",
        "  return scalar_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-9xhY76bMaPd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########################## ENCODER NETWORK #################################\n",
        "# 5 layers\n",
        "# starts with 32x32x32 input, ends with Fully Connected layer (flattened 7x7x7 output of 4th convolutional layer)\n",
        "\n",
        "# ???\n",
        "# Glorot initialization is deafault (glorot_uniform) - Keras has glorot_normal \n",
        "# and glorot_uniform, paper is unclear which should be used\n",
        "\n",
        "# Input is 32x32x32 point cloud\n",
        "voxel_input = Input(shape=(32, 32, 32, 1))\n",
        "\n",
        "# First convolutional layer: outputs 30x30x30\n",
        "encode_c1 = Conv3D(8, kernel_size=3, activation='elu', padding='valid',\n",
        "              data_format='channels_last', kernel_regularizer=l2(l=0.01))(voxel_input)\n",
        "encode_b1 = BatchNormalization()(encode_c1)\n",
        "\n",
        "# Second convolutional layer: outputs 15x15x15 (downsamples via striding)\n",
        "encode_c2 = Conv3D(16, kernel_size=3, activation='elu', padding='same',\n",
        "              strides=(2, 2, 2), kernel_regularizer=l2(l=0.01))(encode_b1)\n",
        "encode_b2 = BatchNormalization()(encode_c2)\n",
        "\n",
        "# Third convolutional layer: outputs 13x13x13\n",
        "encode_c3 = Conv3D(32, kernel_size=3, activation='elu', padding='valid',\n",
        "                  kernel_regularizer=l2(l=0.01))(encode_b2)\n",
        "encode_b3 = BatchNormalization()(encode_c3)\n",
        "\n",
        "# Fourth convolutional layer: outputs 7x7x7 (downsamples via striding)\n",
        "encode_c4 = Conv3D(64, kernel_size=3, activation='elu', padding='same', \n",
        "              strides=(2, 2, 2), kernel_regularizer=l2(l=0.01))(encode_b3)\n",
        "encode_b4 = BatchNormalization()(encode_c4)\n",
        "\n",
        "# Fifth layer, fully connected: outputs 343\n",
        "encode_f5 = Flatten()(encode_b4)\n",
        "encode_b5 = BatchNormalization()(encode_f5)\n",
        "\n",
        "# Sixth layer - LATENT LAYER: outputs 100\n",
        "latent = Dense(100, use_bias=True, activation='elu',\n",
        "               kernel_regularizer=l2(l=0.01))(encode_b5)\n",
        "\n",
        "encoder = Model(inputs=voxel_input, outputs=latent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H4MBNrV5Kr-m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "1862a937-7fae-4d47-b4f4-bc65d3ac47e4"
      },
      "cell_type": "code",
      "source": [
        "# Structure/info about encoder\n",
        "encoder.compile(optimizer='adam', loss='logcosh', metrics=['accuracy'])\n",
        "encoder.summary()\n",
        "\n",
        "# Testing encoder on dummy data\n",
        "dummy_data = np.random.rand(100, 32, 32, 32, 1)\n",
        "# Labels don't matter for us, we only care about the model's ouptut, output must be in the shape of final layer!!!\n",
        "dumb_labels = np.random.rand(100, 100)\n",
        "encoder.fit(dummy_data, dumb_labels, shuffle=True)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        (None, 32, 32, 32, 1)     0         \n",
            "_________________________________________________________________\n",
            "conv3d_56 (Conv3D)           (None, 30, 30, 30, 8)     224       \n",
            "_________________________________________________________________\n",
            "batch_normalization_96 (Batc (None, 30, 30, 30, 8)     32        \n",
            "_________________________________________________________________\n",
            "conv3d_57 (Conv3D)           (None, 15, 15, 15, 16)    3472      \n",
            "_________________________________________________________________\n",
            "batch_normalization_97 (Batc (None, 15, 15, 15, 16)    64        \n",
            "_________________________________________________________________\n",
            "conv3d_58 (Conv3D)           (None, 13, 13, 13, 32)    13856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_98 (Batc (None, 13, 13, 13, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv3d_59 (Conv3D)           (None, 7, 7, 7, 64)       55360     \n",
            "_________________________________________________________________\n",
            "batch_normalization_99 (Batc (None, 7, 7, 7, 64)       256       \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 21952)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_100 (Bat (None, 21952)             87808     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 100)               2195300   \n",
            "=================================================================\n",
            "Total params: 2,356,500\n",
            "Trainable params: 2,312,356\n",
            "Non-trainable params: 44,144\n",
            "_________________________________________________________________\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 3.1501 - acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda2657e1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "_WBpRlZn0YhE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########################## DECODER NETWORK ################################# \n",
        "\n",
        "# Latent space of 1D dimension 100 is input for decoder\n",
        "decoder_input = Input(shape=(100,))\n",
        "\n",
        "# First layer of decoder, fully connected layer: outputs 343\n",
        "decode_f1 = Dense(343, use_bias=True, activation='elu',\n",
        "                 kernel_regularizer=l2(l=0.01))(decoder_input)\n",
        "decode_b1 = BatchNormalization()(decode_f1)\n",
        "\n",
        "# Reshape layer from fully connected to 7x7x7\n",
        "# must add spacial dimension for convolutions to work\n",
        "decode_reshape = Reshape((7, 7, 7, 1), input_shape=(343,))(decode_b1) \n",
        "# Second convolutional layer: convolutes fully connected layer into 7x7x7 (with 64 filters)\n",
        "# decode_c2 = Conv3DTranspose(64, kernel_size=3, activation='elu', \n",
        "#                    padding='same')(decode_reshape)\n",
        "\n",
        "# Second convolutional layer: convolutes fully connected layer into 7x7x7\n",
        "# ??? Not exactly sure how to get from 1D to 3D convolution...(dimension wise)\n",
        "# decode_reshape = Reshape((7, 7, 7, 1), input_shape=(343,))(decode_b1) # must add spacial dimension for convolutions to work\n",
        "decode_c2 = Conv3D(64, kernel_size=3, activation='elu', \n",
        "                   padding='same', kernel_regularizer=l2(l=0.01))(decode_reshape)\n",
        "decode_b2 = BatchNormalization()(decode_c2)\n",
        "\n",
        "# Third layer (second convolutional layer): outputs 15x15x15\n",
        "decode_c3 = Conv3DTranspose(32, kernel_size=3, activation='elu',padding='valid',\n",
        "                   strides=(2, 2, 2), kernel_regularizer=l2(l=0.01))(decode_b2)\n",
        "decode_b3 = BatchNormalization()(decode_c3)\n",
        "\n",
        "# Fourth convolutional layer: outputs 15x15x15\n",
        "decode_c4 = Conv3DTranspose(16, kernel_size=3, activation='elu', \n",
        "                   padding='same', kernel_regularizer=l2(l=0.01))(decode_b3)\n",
        "decode_b4 = BatchNormalization()(decode_c4)\n",
        "\n",
        "# Fifth convolutional layer: outputs 32x32x32 \n",
        "decode_c5 = Conv3DTranspose(8, kernel_size=3, activation='elu', padding='valid',\n",
        "                   strides=(2, 2, 2), output_padding=1, kernel_regularizer=l2(l=0.01))(decode_b4)\n",
        "decode_b5 = BatchNormalization()(decode_c5)\n",
        "\n",
        "# OUTPUT LAYERRRRRRRR!!! Sigmoid function to output probability each voxel is filled\n",
        "decode_output = Conv3DTranspose(1, kernel_size=3, activation='sigmoid', \n",
        "                   padding='same', kernel_regularizer=l2(l=0.01))(decode_b5)\n",
        "\n",
        "decoder = Model(inputs=decoder_input, outputs=decode_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r9iODLsKK6eK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "11ae4b01-ddee-4477-f5ec-b480ad67561c"
      },
      "cell_type": "code",
      "source": [
        "# Structure/info about decoder\n",
        "decoder.compile(optimizer='adam', loss='logcosh', metrics=['accuracy'])\n",
        "decoder.summary()\n",
        "\n",
        "# Testing decoder on dummy data\n",
        "dummy_data = np.random.rand(100, 100)\n",
        "# Labels don't matter for us, we only care about the model's ouptut, output must be in the shape of final layer!!!\n",
        "dumb_labels = np.random.rand(100, 32, 32, 32, 1)\n",
        "decoder.fit(dummy_data, dumb_labels, shuffle=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 343)               34643     \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 343)               1372      \n",
            "_________________________________________________________________\n",
            "reshape_6 (Reshape)          (None, 7, 7, 7, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv3d_14 (Conv3D)           (None, 7, 7, 7, 64)       1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 7, 7, 7, 64)       256       \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_21 (Conv3DT (None, 15, 15, 15, 32)    55328     \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 15, 15, 15, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_22 (Conv3DT (None, 15, 15, 15, 16)    13840     \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 15, 15, 15, 16)    64        \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_23 (Conv3DT (None, 32, 32, 32, 8)     3464      \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 32, 32, 32, 8)     32        \n",
            "_________________________________________________________________\n",
            "conv3d_transpose_24 (Conv3DT (None, 32, 32, 32, 1)     217       \n",
            "=================================================================\n",
            "Total params: 111,136\n",
            "Trainable params: 110,210\n",
            "Non-trainable params: 926\n",
            "_________________________________________________________________\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.0608 - acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda2e05e7d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "Wco_lWONT1iZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "2fb42610-d036-409e-ec78-99d5a69cb171"
      },
      "cell_type": "code",
      "source": [
        "################################# AUTOENCODER ###############################\n",
        "reconstruction = decoder(encoder(voxel_input))\n",
        "ae = Model(inputs=voxel_input, outputs=reconstruction)\n",
        "\n",
        "ae.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        (None, 32, 32, 32, 1)     0         \n",
            "_________________________________________________________________\n",
            "model_24 (Model)             (None, 100)               2356500   \n",
            "_________________________________________________________________\n",
            "model_13 (Model)             (None, 32, 32, 32, 1)     111136    \n",
            "=================================================================\n",
            "Total params: 2,467,636\n",
            "Trainable params: 2,422,566\n",
            "Non-trainable params: 45,070\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J7blrfOuK8v4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train with: model.compile(optimizer='binary_crossentropy', loss='logcosh', metrics=['accuracy'])\n",
        "ae.compile(optimizer='adam', loss=lambda_binary_crossentropy)\n",
        "\n",
        "# ae.fit(data, epochs=100)\n",
        "# then: model.fit(data, data_labels, shuffle=True) where labels don't matter for us"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S4mT8h0T8NuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# OLD ENCODER NETWORK IMPLEMENTATION: (doesn't use functional keras)\n",
        "# vae = Sequential()\n",
        "# # First convolutional layer\n",
        "# vae.add(Conv3D(8, kernel_size=3, activation='elu', padding='valid', \n",
        "#                    data_format='channels_last', input_shape=(32, 32, 32, 1))) \n",
        "# vae.add(BatchNormalization())\n",
        "\n",
        "# # Second convolutional layer, downsampling through strided convolutions \n",
        "# # (default striding is 1x1x1, so up this to 2x2x2)\n",
        "# vae.add(Conv3D(16, kernel_size=3, activation='elu', padding='same', strides=(2, 2, 2))) \n",
        "# vae.add(BatchNormalization())\n",
        "\n",
        "# # # Third convolutional layer\n",
        "# vae.add(Conv3D(32, kernel_size=3, activation='elu', padding='valid'))\n",
        "# vae.add(BatchNormalization())\n",
        "\n",
        "# # # Fourth convolutional layer, downsampling through strided convolutions\n",
        "# vae.add(Conv3D(64, kernel_size=3, activation='elu', padding='same', strides=(2, 2, 2)))\n",
        "# vae.add(BatchNormalization())\n",
        "\n",
        "# # # Fully connected layer and latent layer\n",
        "# # # Fully connected: Dense layer that takes in flattened output of previous layer \n",
        "# # # Latent layer: output of fully connected layer is 100 dimensional latent space\n",
        "# vae.add(Flatten())\n",
        "# vae.add(Dense(100, use_bias=True, activation='elu'))\n",
        "\n",
        "# vae.compile(optimizer='adam', loss='logcosh', metrics=['accuracy'])\n",
        "# vae.summary()\n",
        "\n",
        "\n",
        "# OLD DECODER NETWORK IMPLEMENTATION\n",
        "# # First layer of decoder\n",
        "# vae.add(Dense(343, use_bias=True, activation='elu'))\n",
        "\n",
        "# # Convolution layer that convolutes fully connected layer into 7x7x7\n",
        "# vae.add(Conv1D(64, kernel_size=3, activation='elu', padding='same'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rF-4rPBy5Sz9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# is now part of encoder, not separate\n",
        "########################## LATENT LAYER #################################\n",
        "# \"All but the output layer are Batch Normalized\" - this is interpreted as the output \n",
        "# layer of the sigmoid AND the latent layer are not Batch Normalized but ???\n",
        "\n",
        "# input of latent layer is last layer of encoder network\n",
        "# latent_input = Input(shape=(21952,))\n",
        "\n",
        "# # Sixth layer - LATENT LAYER: outputs 100\n",
        "# latent = Dense(100, use_bias=True, activation='elu',\n",
        "#                kernel_regularizer=l2(l=0.01))(latent_input)\n",
        "\n",
        "# latent_layer = Model(inputs=latent_input, outputs=latent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZOjy2YrOK1LF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Structure/info about latent layer\n",
        "# latent_layer.compile(optimizer='adam', loss='logcosh', metrics=['accuracy'])\n",
        "# latent_layer.summary()\n",
        "\n",
        "# # Testing latent layer on dummy data\n",
        "# dummy_data = np.random.rand(100, 21952)\n",
        "# fake_labels = np.random.rand(100, 100) \n",
        "# latent_layer.fit(dummy_data, fake_labels, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}